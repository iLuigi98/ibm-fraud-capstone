{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a85f0a-40f2-42a0-9bee-448593cb6a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rezam\\anaconda3\\envs\\Capstone\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda torch: 2.5.1 cuda: 12.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device, \"torch:\", torch.__version__, \"cuda:\", torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ee9c0f-817d-4f2c-bce5-ebc8f3fb8e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5078345, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/01 00:20</td>\n",
       "      <td>10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/01 00:20</td>\n",
       "      <td>3208</td>\n",
       "      <td>8000F4580</td>\n",
       "      <td>1</td>\n",
       "      <td>8000F5340</td>\n",
       "      <td>0.01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>0.01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01 00:00</td>\n",
       "      <td>3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>14675.57</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>14675.57</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/01 00:02</td>\n",
       "      <td>12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>2806.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2806.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/01 00:06</td>\n",
       "      <td>10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>36682.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>36682.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "0  2022/09/01 00:20         10  8000EBD30       10  8000EBD30   \n",
       "1  2022/09/01 00:20       3208  8000F4580        1  8000F5340   \n",
       "2  2022/09/01 00:00       3209  8000F4670     3209  8000F4670   \n",
       "3  2022/09/01 00:02         12  8000F5030       12  8000F5030   \n",
       "4  2022/09/01 00:06         10  8000F5200       10  8000F5200   \n",
       "\n",
       "   Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
       "0          3697.34          US Dollar      3697.34        US Dollar   \n",
       "1             0.01          US Dollar         0.01        US Dollar   \n",
       "2         14675.57          US Dollar     14675.57        US Dollar   \n",
       "3          2806.97          US Dollar      2806.97        US Dollar   \n",
       "4         36682.97          US Dollar     36682.97        US Dollar   \n",
       "\n",
       "  Payment Format  Is Laundering  \n",
       "0   Reinvestment              0  \n",
       "1         Cheque              0  \n",
       "2   Reinvestment              0  \n",
       "3   Reinvestment              0  \n",
       "4   Reinvestment              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change if needed\n",
    "CSV_FILE = \"HI-Small_Trans.csv\"\n",
    "\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17502f7a-24ed-49e2-a2bf-8daa274e718e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pos rate: 0.000831963956761504\n",
      "test  pos rate: 0.001769277195621802\n",
      "rows train/test: 4062676 1015669\n"
     ]
    }
   ],
   "source": [
    "df[\"ts\"] = pd.to_datetime(df[\"Timestamp\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"ts\"]).sort_values(\"ts\").reset_index(drop=True)\n",
    "\n",
    "# Rename for sanity\n",
    "df = df.rename(columns={\n",
    "    \"Account\": \"src_acct\",\n",
    "    \"Account.1\": \"dst_acct\",\n",
    "    \"From Bank\": \"src_bank\",\n",
    "    \"To Bank\": \"dst_bank\",\n",
    "    \"Amount Paid\": \"amt_paid\",\n",
    "    \"Amount Received\": \"amt_recv\",\n",
    "    \"Payment Currency\": \"pay_ccy\",\n",
    "    \"Receiving Currency\": \"recv_ccy\",\n",
    "    \"Payment Format\": \"pay_fmt\",\n",
    "    \"Is Laundering\": \"y\"\n",
    "})\n",
    "\n",
    "# ensure labels 0/1 int\n",
    "df[\"y\"] = df[\"y\"].astype(int)\n",
    "\n",
    "# time split\n",
    "cut = int(len(df) * 0.8)\n",
    "train_df = df.iloc[:cut].copy()\n",
    "test_df  = df.iloc[cut:].copy()\n",
    "\n",
    "print(\"train pos rate:\", train_df[\"y\"].mean())\n",
    "print(\"test  pos rate:\", test_df[\"y\"].mean())\n",
    "print(\"rows train/test:\", len(train_df), len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ccebb7-ab3e-4ca0-9606-312fc64246d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nodes: 515080\n",
      "train edges: 4062676 test edges: 1015669\n",
      "edge_attr dim: 4\n"
     ]
    }
   ],
   "source": [
    "# Map account IDs to contiguous node ids\n",
    "all_accts = pd.Index(pd.concat([df[\"src_acct\"], df[\"dst_acct\"]], ignore_index=True).astype(str).unique())\n",
    "acct2id = {a:i for i,a in enumerate(all_accts)}\n",
    "num_nodes = len(all_accts)\n",
    "print(\"num_nodes:\", num_nodes)\n",
    "\n",
    "def make_edge_table(dfx: pd.DataFrame):\n",
    "    src = dfx[\"src_acct\"].astype(str).map(acct2id).astype(np.int64).to_numpy()\n",
    "    dst = dfx[\"dst_acct\"].astype(str).map(acct2id).astype(np.int64).to_numpy()\n",
    "    y   = dfx[\"y\"].astype(np.int64).to_numpy()\n",
    "\n",
    "    # numeric amount feature(s) (log helps)\n",
    "    amt = dfx[\"amt_paid\"].astype(float).to_numpy()\n",
    "    amt = np.log1p(np.clip(amt, 0, None))  # log(1+amt)\n",
    "\n",
    "    # categorical -> codes (fast, compact)\n",
    "    pay_ccy = dfx[\"pay_ccy\"].astype(str).astype(\"category\").cat.codes.to_numpy()\n",
    "    recv_ccy = dfx[\"recv_ccy\"].astype(str).astype(\"category\").cat.codes.to_numpy()\n",
    "    pay_fmt = dfx[\"pay_fmt\"].astype(str).astype(\"category\").cat.codes.to_numpy()\n",
    "\n",
    "    # stack edge features (float32)\n",
    "    edge_attr = np.stack([amt, pay_ccy, recv_ccy, pay_fmt], axis=1).astype(np.float32)\n",
    "    return src, dst, y, edge_attr\n",
    "\n",
    "src_tr, dst_tr, y_tr, eattr_tr = make_edge_table(train_df)\n",
    "src_te, dst_te, y_te, eattr_te = make_edge_table(test_df)\n",
    "\n",
    "print(\"train edges:\", len(y_tr), \"test edges:\", len(y_te))\n",
    "print(\"edge_attr dim:\", eattr_tr.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41a37073-1d92-49cf-bd8c-0ca6f4dbf728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph edges from TRAIN only\n",
    "edge_index_train = torch.tensor(\n",
    "    np.stack([src_tr, dst_tr], axis=0),\n",
    "    dtype=torch.long\n",
    ")\n",
    "\n",
    "data = Data(edge_index=edge_index_train, num_nodes=num_nodes)\n",
    "\n",
    "# For link prediction, we provide edge_label_index + edge_label\n",
    "edge_label_index_tr = torch.tensor(np.stack([src_tr, dst_tr], axis=0), dtype=torch.long)\n",
    "edge_label_tr = torch.tensor(y_tr, dtype=torch.float32)\n",
    "\n",
    "edge_label_index_te = torch.tensor(np.stack([src_te, dst_te], axis=0), dtype=torch.long)\n",
    "edge_label_te = torch.tensor(y_te, dtype=torch.float32)\n",
    "\n",
    "# Neighbor sampling sizes: keep small to avoid OOM\n",
    "num_neighbors = [10, 5]\n",
    "batch_size = 4096\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=data,\n",
    "    num_neighbors=num_neighbors,\n",
    "    batch_size=batch_size,\n",
    "    edge_label_index=edge_label_index_tr,\n",
    "    edge_label=edge_label_tr,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = LinkNeighborLoader(\n",
    "    data=data,\n",
    "    num_neighbors=num_neighbors,\n",
    "    batch_size=batch_size,\n",
    "    edge_label_index=edge_label_index_te,\n",
    "    edge_label=edge_label_te,\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba9b861c-6dfb-4d0c-b3b3-1ac37c00436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_weight: 1200.97509765625\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class SAGEEdgeClassifier(nn.Module):\n",
    "    def __init__(self, num_nodes, emb_dim=64, hidden=64, edge_feat_dim=4):\n",
    "        super().__init__()\n",
    "        self.node_emb = nn.Embedding(num_nodes, emb_dim)\n",
    "\n",
    "        self.conv1 = SAGEConv(emb_dim, hidden)\n",
    "        self.conv2 = SAGEConv(hidden, emb_dim)\n",
    "\n",
    "        # edge scorer: [h_u, h_v, |diff|, edge_feat] -> logit\n",
    "        in_dim = emb_dim*3 + edge_feat_dim\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(h, edge_index)\n",
    "        return h\n",
    "\n",
    "    def forward(self, batch, edge_feat):\n",
    "        # batch has n_id (global node ids for this subgraph)\n",
    "        x = self.node_emb(batch.n_id)\n",
    "        h = self.encode(x, batch.edge_index)\n",
    "\n",
    "        # edge_label_index is LOCAL indices into batch nodes\n",
    "        src = batch.edge_label_index[0]\n",
    "        dst = batch.edge_label_index[1]\n",
    "\n",
    "        hs = h[src]\n",
    "        hd = h[dst]\n",
    "        feat = torch.cat([hs, hd, torch.abs(hs - hd), edge_feat], dim=1)\n",
    "        return self.mlp(feat).view(-1)\n",
    "\n",
    "model = SAGEEdgeClassifier(num_nodes=num_nodes, emb_dim=64, hidden=64, edge_feat_dim=eattr_tr.shape[1]).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# pos_weight for BCE: (neg/pos)\n",
    "pos = y_tr.sum()\n",
    "neg = len(y_tr) - pos\n",
    "pos_weight = torch.tensor([neg / (pos + 1e-9)], dtype=torch.float32, device=device)\n",
    "crit = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "print(\"pos_weight:\", pos_weight.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c181f4db-4f88-4b32-9261-a7f535b51a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_key2idx(src, dst):\n",
    "    # key as 64-bit packed int to avoid python tuple overhead\n",
    "    # pack: (src << 32) | dst  (works if node ids < 2^32)\n",
    "    key = (src.astype(np.int64) << 32) | dst.astype(np.int64)\n",
    "    return {int(k): i for i, k in enumerate(key)}\n",
    "\n",
    "train_key2idx = build_key2idx(src_tr, dst_tr)\n",
    "test_key2idx  = build_key2idx(src_te, dst_te)\n",
    "\n",
    "eattr_tr_t = torch.tensor(eattr_tr, dtype=torch.float32, device=device)\n",
    "eattr_te_t = torch.tensor(eattr_te, dtype=torch.float32, device=device)\n",
    "\n",
    "def get_edge_feat_for_batch(batch, key2idx, edge_attr_tensor):\n",
    "    # local edge endpoints -> global node ids\n",
    "    src_local = batch.edge_label_index[0]\n",
    "    dst_local = batch.edge_label_index[1]\n",
    "    src_global = batch.n_id[src_local].detach().cpu().numpy().astype(np.int64)\n",
    "    dst_global = batch.n_id[dst_local].detach().cpu().numpy().astype(np.int64)\n",
    "\n",
    "    keys = (src_global << 32) | dst_global\n",
    "    idxs = [key2idx[int(k)] for k in keys]\n",
    "    return edge_attr_tensor[idxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98be8ac5-e45c-47f7-b6c7-c1f927ebcca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1: 100%|█████████████████████████████████████████████████████████████████| 992/992 [00:45<00:00, 21.70it/s]\n",
      "eval epoch 1: 100%|██████████████████████████████████████████████████████████████████| 248/248 [00:05<00:00, 46.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | loss 620.1835 | PR-AUC 0.049736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 2: 100%|█████████████████████████████████████████████████████████████████| 992/992 [00:48<00:00, 20.53it/s]\n",
      "eval epoch 2: 100%|██████████████████████████████████████████████████████████████████| 248/248 [00:05<00:00, 45.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 02 | loss 367.1571 | PR-AUC 0.076606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 3: 100%|█████████████████████████████████████████████████████████████████| 992/992 [00:49<00:00, 20.17it/s]\n",
      "eval epoch 3: 100%|██████████████████████████████████████████████████████████████████| 248/248 [00:05<00:00, 45.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 03 | loss 222.7732 | PR-AUC 0.105318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 4: 100%|█████████████████████████████████████████████████████████████████| 992/992 [00:48<00:00, 20.51it/s]\n",
      "eval epoch 4: 100%|██████████████████████████████████████████████████████████████████| 248/248 [00:05<00:00, 43.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 04 | loss 142.6221 | PR-AUC 0.124013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 5: 100%|█████████████████████████████████████████████████████████████████| 992/992 [00:48<00:00, 20.45it/s]\n",
      "eval epoch 5: 100%|██████████████████████████████████████████████████████████████████| 248/248 [00:05<00:00, 45.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 05 | loss 94.6748 | PR-AUC 0.127497\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"train epoch {epoch}\"):\n",
    "        batch = batch.to(device)\n",
    "        edge_feat = get_edge_feat_for_batch(batch, train_key2idx, eattr_tr_t)\n",
    "\n",
    "        logits = model(batch, edge_feat)\n",
    "        loss = crit(logits, batch.edge_label.to(device))\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += float(loss.item())\n",
    "\n",
    "    # eval\n",
    "    model.eval()\n",
    "    probs, ys = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=f\"eval epoch {epoch}\"):\n",
    "            batch = batch.to(device)\n",
    "            edge_feat = get_edge_feat_for_batch(batch, test_key2idx, eattr_te_t)\n",
    "\n",
    "            logit = model(batch, edge_feat)\n",
    "            p = torch.sigmoid(logit).detach().cpu().numpy()\n",
    "            y = batch.edge_label.detach().cpu().numpy()\n",
    "\n",
    "            probs.append(p)\n",
    "            ys.append(y)\n",
    "\n",
    "    y_true = np.concatenate(ys)\n",
    "    y_prob = np.concatenate(probs)\n",
    "    pr_auc = average_precision_score(y_true, y_prob)\n",
    "\n",
    "    print(f\"epoch {epoch:02d} | loss {total_loss:.4f} | PR-AUC {pr_auc:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f444c763-a734-4fea-ab11-e9f3c7bb5e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (4062676, 260) X_test: (1015669, 260)\n",
      "pos rate train/test: 0.000831963956761504 0.001769277195621802\n"
     ]
    }
   ],
   "source": [
    "# Pull node embeddings (fast and stable)\n",
    "H = model.node_emb.weight.detach().cpu().numpy()  # (num_nodes, emb_dim)\n",
    "\n",
    "def build_hybrid_X(src, dst, edge_attr, H):\n",
    "    Hs = H[src]\n",
    "    Hd = H[dst]\n",
    "    X = np.hstack([\n",
    "        Hs, Hd,\n",
    "        np.abs(Hs - Hd),\n",
    "        Hs * Hd,\n",
    "        edge_attr\n",
    "    ]).astype(np.float32)\n",
    "    return X\n",
    "\n",
    "X_train = build_hybrid_X(src_tr, dst_tr, eattr_tr, H)\n",
    "X_test  = build_hybrid_X(src_te, dst_te, eattr_te, H)\n",
    "\n",
    "y_train = y_tr.astype(int)\n",
    "y_test  = y_te.astype(int)\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"X_test:\", X_test.shape)\n",
    "print(\"pos rate train/test:\", y_train.mean(), y_test.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c20e1e5-a992-47b3-a7f4-f7767e386a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid (HGB weighted) PR-AUC: 0.13147641569564023\n",
      "Precision@1%: 0.057207562032296176\n",
      "Recall@1%: 0.32331663884233536\n"
     ]
    }
   ],
   "source": [
    "# sample weights: upweight positives\n",
    "w_pos = (len(y_train) - y_train.sum()) / (y_train.sum() + 1e-9)\n",
    "sample_weight = np.where(y_train == 1, w_pos, 1.0).astype(np.float32)\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    max_iter=300,\n",
    ")\n",
    "hgb.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "\n",
    "p = hgb.predict_proba(X_test)[:, 1]\n",
    "pr_auc = average_precision_score(y_test, p)\n",
    "print(\"Hybrid (HGB weighted) PR-AUC:\", pr_auc)\n",
    "\n",
    "# Precision@k / Recall@k at top 1%\n",
    "k = int(0.01 * len(p))\n",
    "top = np.argsort(p)[-k:]\n",
    "precision_at_1pct = y_test[top].mean()\n",
    "recall_at_1pct = y_test[top].sum() / (y_test.sum() + 1e-9)\n",
    "print(\"Precision@1%:\", precision_at_1pct)\n",
    "print(\"Recall@1%:\", recall_at_1pct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ab77061-c6d8-4bf9-9104-111c47a6150e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge-only skipped (missing vars): name 'edge_attr_tr_np' is not defined\n",
      "Hybrid skipped (missing vars): name 'p_hybrid' is not defined\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision@1%</th>\n",
       "      <th>Recall@1%</th>\n",
       "      <th>Alerts@1%</th>\n",
       "      <th>Accuracy@0.5</th>\n",
       "      <th>Prec@0.5</th>\n",
       "      <th>Rec@0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GNN-only</td>\n",
       "      <td>0.127497</td>\n",
       "      <td>0.930089</td>\n",
       "      <td>0.06794</td>\n",
       "      <td>0.383973</td>\n",
       "      <td>10156</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.014664</td>\n",
       "      <td>0.521981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model    PR_AUC   ROC_AUC  Precision@1%  Recall@1%  Alerts@1%  \\\n",
       "0  GNN-only  0.127497  0.930089       0.06794   0.383973      10156   \n",
       "\n",
       "   Accuracy@0.5  Prec@0.5   Rec@0.5  \n",
       "0        0.9371  0.014664  0.521981  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONE-CELL: build a results table for Edge-only HGB, GNN-only, and Hybrid\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "def eval_metrics(y_true, p, top_frac=0.01):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    p = np.asarray(p).astype(float)\n",
    "\n",
    "    pr_auc = average_precision_score(y_true, p)\n",
    "    roc_auc = roc_auc_score(y_true, p) if len(np.unique(y_true)) > 1 else np.nan\n",
    "\n",
    "    k = max(1, int(top_frac * len(p)))\n",
    "    top_idx = np.argsort(p)[-k:]\n",
    "    prec_at = y_true[top_idx].mean()\n",
    "    rec_at = y_true[top_idx].sum() / (y_true.sum() + 1e-9)\n",
    "\n",
    "    # threshold @0.5 (mostly for completeness; not great under heavy imbalance)\n",
    "    y_pred = (p >= 0.5).astype(int)\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"PR_AUC\": pr_auc,\n",
    "        \"ROC_AUC\": roc_auc,\n",
    "        \"Precision@1%\": prec_at,\n",
    "        \"Recall@1%\": rec_at,\n",
    "        \"Alerts@1%\": k,\n",
    "        \"Accuracy@0.5\": acc,\n",
    "        \"Prec@0.5\": prec,\n",
    "        \"Rec@0.5\": rec,\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "\n",
    "# ----- Edge-only baseline (HGB) -----\n",
    "# expects: edge_attr_tr_np, edge_attr_te_np, y_train, y_test\n",
    "try:\n",
    "    X_edge_train = edge_attr_tr_np\n",
    "    X_edge_test  = edge_attr_te_np\n",
    "    y_tr = np.asarray(y_train).astype(int)\n",
    "    y_te = np.asarray(y_test).astype(int)\n",
    "\n",
    "    w_pos = (len(y_tr) - y_tr.sum()) / (y_tr.sum() + 1e-9)\n",
    "    sample_weight = np.where(y_tr == 1, w_pos, 1.0).astype(np.float32)\n",
    "\n",
    "    hgb_edge = HistGradientBoostingClassifier(max_depth=6, learning_rate=0.1, max_iter=300)\n",
    "    hgb_edge.fit(X_edge_train, y_tr, sample_weight=sample_weight)\n",
    "    p_edge = hgb_edge.predict_proba(X_edge_test)[:, 1]\n",
    "\n",
    "    m = eval_metrics(y_te, p_edge)\n",
    "    m[\"Model\"] = \"Edge-only (HGB)\"\n",
    "    rows.append(m)\n",
    "except NameError as e:\n",
    "    print(\"Edge-only skipped (missing vars):\", e)\n",
    "\n",
    "# ----- GNN-only -----\n",
    "# expects: ys, probs from your GNN eval loop OR y_true_gnn, y_prob_gnn\n",
    "try:\n",
    "    if \"y_true_gnn\" in globals() and \"y_prob_gnn\" in globals():\n",
    "        y_gnn = y_true_gnn\n",
    "        p_gnn = y_prob_gnn\n",
    "    else:\n",
    "        y_gnn = np.concatenate(ys)\n",
    "        p_gnn = np.concatenate(probs)\n",
    "\n",
    "    m = eval_metrics(y_gnn, p_gnn)\n",
    "    m[\"Model\"] = \"GNN-only\"\n",
    "    rows.append(m)\n",
    "except NameError as e:\n",
    "    print(\"GNN-only skipped (missing vars):\", e)\n",
    "\n",
    "# ----- Hybrid -----\n",
    "# expects: p_hybrid and y_test (or y_te)\n",
    "try:\n",
    "    p_h = p_hybrid\n",
    "    y_te = np.asarray(y_test).astype(int)\n",
    "\n",
    "    m = eval_metrics(y_te, p_h)\n",
    "    m[\"Model\"] = \"Hybrid\"\n",
    "    rows.append(m)\n",
    "except NameError as e:\n",
    "    print(\"Hybrid skipped (missing vars):\", e)\n",
    "\n",
    "results_df = pd.DataFrame(rows)[\n",
    "    [\"Model\",\"PR_AUC\",\"ROC_AUC\",\"Precision@1%\",\"Recall@1%\",\"Alerts@1%\",\"Accuracy@0.5\",\"Prec@0.5\",\"Rec@0.5\"]\n",
    "].sort_values(\"PR_AUC\", ascending=False)\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32405b69-ab77-46f8-b47b-89d1e176f524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Capstone)",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
